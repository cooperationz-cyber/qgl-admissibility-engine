"""
QGL Lexer - Tokenizes QGL code and rejects forbidden syntax immediately
NOW INCLUDES QUANTUM NOTATION: |0‚ü©, |1‚ü©, |+‚ü©, |->, |0>‚äï|1>
"""
import re

class QGLLexer:
    """Tokenizes QGL - REJECTS invalid syntax at tokenization stage"""
    
    # Tokens that CANNOT appear in QGL
    FORBIDDEN_TOKENS = {
        'for', 'while', 'repeat', 'iterate', 'loop',
        'time', 'step', 'clock', 'tick', 'second', 'minute',
        'evolve', 'simulate', 'optimize', 'minimize', 'maximize',
        'search', 'find', 'compute', 'calculate', 'solve',
        'member', 'contains', 'in', '‚àà'  # No set membership operators
    }
    
    # Allowed tokens - NOW INCLUDES QUANTUM_STATE
    TOKEN_PATTERNS = [
        ('QUANTUM_STATE', r'\|[0-9+\-‚Üë‚Üì01Œ±Œ≤Œ≥œÜœà][^|]*\‚ü©?'),  # NEW: Quantum states |0‚ü©, |1‚ü©, |+‚ü©, |-‚ü©, |œà‚ü©
        ('BOUNDARY', r'boundary\b'),
        ('DOMAIN', r'domain\b'),
        ('QUBIT', r'qubit\b'),
        ('IDENTIFIER', r'[A-Za-z_][A-Za-z0-9_]*'),
        ('LBRACE', r'\{'),
        ('RBRACE', r'\}'),
        ('LBRACKET', r'\['),
        ('RBRACKET', r'\]'),
        ('EQUALS', r'='),
        ('PLUS', r'‚äï'),
        ('COMMA', r','),
        ('PIPE', r'\|'),  # NEW: Single | character for quantum notation
        ('ANGLE_BRACKET', r'‚ü®|‚ü©|>|<'),  # NEW: Quantum brackets
        ('WHITESPACE', r'\s+'),
        ('COMMENT', r'//.*'),
    ]
    
    def __init__(self):
        self.tokens = []
        self.position = 0
    
    def tokenize(self, code):
        """Tokenize QGL code, rejecting forbidden syntax immediately"""
        self.tokens = []
        self.position = 0
        
        # Pre-process: Handle common quantum notation variations
        # Replace |0> with |0‚ü©, |1> with |1‚ü©, etc. for consistency
        code = self._normalize_quantum_notation(code)
        
        # Remove comments first (anything after //)
        lines = code.split('\n')
        clean_lines = []
        for line in lines:
            if '//' in line:
                line = line.split('//')[0]  # Keep only part before comment
            clean_lines.append(line)
        clean_code = '\n'.join(clean_lines)
        
        # Check for forbidden tokens (ignoring comments)
        for forbidden in self.FORBIDDEN_TOKENS:
            pattern = r'\b' + re.escape(forbidden) + r'\b'
            if re.search(pattern, clean_code):
                raise SyntaxError(
                    f"FORBIDDEN SYNTAX: '{forbidden}' cannot appear in QGL. "
                    f"QGL is structural, not procedural."
                )
        
        # Tokenize allowed patterns
        while self.position < len(code):
            matched = False
            
            for token_type, pattern in self.TOKEN_PATTERNS:
                regex = re.compile(pattern)
                match = regex.match(code, self.position)
                
                if match:
                    matched = True
                    value = match.group(0)
                    
                    # Skip whitespace and comments
                    if token_type not in ['WHITESPACE', 'COMMENT']:
                        # Special handling for quantum states
                        if token_type == 'QUANTUM_STATE':
                            # Normalize quantum state representation
                            value = self._normalize_quantum_state(value)
                        
                        self.tokens.append((token_type, value))
                    
                    self.position = match.end()
                    break
            
            if not matched:
                # Invalid character
                raise SyntaxError(
                    f"Invalid character at position {self.position}: "
                    f"'{code[self.position]}'\n"
                    f"Context: '{code[max(0,self.position-20):min(len(code),self.position+20)]}'"
                )
        
        return self.tokens
    
    def _normalize_quantum_notation(self, code):
        """Normalize quantum notation for consistent parsing"""
        # Replace common variations
        replacements = [
            (r'\|0\s*\>', '|0‚ü©'),      # |0> ‚Üí |0‚ü©
            (r'\|1\s*\>', '|1‚ü©'),      # |1> ‚Üí |1‚ü©
            (r'\|\+\s*\>', '|+‚ü©'),     # |+> ‚Üí |+‚ü©
            (r'\|\-\s*\>', '|-‚ü©'),     # |-> ‚Üí |-‚ü©
            (r'\|‚Üë\s*\>', '|‚Üë‚ü©'),      # |‚Üë> ‚Üí |‚Üë‚ü©
            (r'\|‚Üì\s*\>', '|‚Üì‚ü©'),      # |‚Üì> ‚Üí |‚Üì‚ü©
            (r'\|œà\s*\>', '|œà‚ü©'),      # |œà> ‚Üí |œà‚ü©
            (r'\|œÜ\s*\>', '|œÜ‚ü©'),      # |œÜ> ‚Üí |œÜ‚ü©
            (r'\|Œ±\s*\>', '|Œ±‚ü©'),      # |Œ±> ‚Üí |Œ±‚ü©
            (r'\|Œ≤\s*\>', '|Œ≤‚ü©'),      # |Œ≤> ‚Üí |Œ≤‚ü©
            (r'\|\s*0\s*\‚ü©', '|0‚ü©'),   # Clean up spaces
            (r'\|\s*1\s*\‚ü©', '|1‚ü©'),
            (r'\|\s*\+\s*\‚ü©', '|+‚ü©'),
            (r'\|\s*\-\s*\‚ü©', '|-‚ü©'),
        ]
        
        for pattern, replacement in replacements:
            code = re.sub(pattern, replacement, code)
        
        return code
    
    def _normalize_quantum_state(self, state):
        """Normalize quantum state representation"""
        # Remove extra spaces
        state = re.sub(r'\s+', '', state)
        
        # Ensure proper bracket format
        if state.startswith('|') and not state.endswith('‚ü©'):
            if state.endswith('>'):
                state = state[:-1] + '‚ü©'
            else:
                state = state + '‚ü©'
        
        return state
    
    def get_tokens(self):
        """Return tokens without whitespace/comments"""
        return [t for t in self.tokens if t[0] not in ['WHITESPACE', 'COMMENT']]
    
    def debug_tokenize(self, code):
        """Debug version that shows what's being tokenized"""
        print("\n" + "="*60)
        print("üß™ LEXER DEBUG MODE")
        print("="*60)
        print(f"Input code:\n{repr(code)}\n")
        
        try:
            tokens = self.tokenize(code)
            print(f"Generated {len(tokens)} tokens:")
            print("-"*40)
            for i, (token_type, value) in enumerate(tokens):
                print(f"{i:3}: {token_type:15} = '{value}'")
            return tokens
        except SyntaxError as e:
            print(f"‚ùå Syntax Error: {e}")
            return []